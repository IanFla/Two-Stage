{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-50caab867d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/linear_model/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mARDRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from ._least_angle import (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[0m\u001b[1;32m     12\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[1;32m     13\u001b[0m from ._coordinate_descent import (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marrayfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_float_array\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvergenceWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetaestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFitFailedWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise_distances_chunked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplained_variance_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmax_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglm_distribution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTweedieDistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from ..utils.validation import (check_array, check_consistent_length,\n\u001b[1;32m     31\u001b[0m                                 _num_samples)\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.1_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.1_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.1_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.1_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.1_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.1_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "from pandas_datareader import DataReader as DR\n",
    "import seaborn as sb\n",
    "import numdifftools as nd\n",
    "from wquantiles import quantile\n",
    "\n",
    "from scipy.stats import multivariate_normal as multi_norm\n",
    "from scipy.stats import multivariate_t as multi_t\n",
    "from scipy.stats import norm,t,truncnorm\n",
    "from scipy.spatial import Delaunay as TRI\n",
    "from scipy.interpolate import LinearNDInterpolator as ITP\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as Linear\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KernelDensity as KDE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DR('^GSPC','yahoo',dt(2010,9,29),dt(2011,7,14))\n",
    "returns=pd.DataFrame(100*np.diff(np.log(data['Adj Close'])),columns=['dlr'])\n",
    "returns.index=data.index.values[1:data.index.values.shape[0]]\n",
    "\n",
    "returns['dlr'].plot()\n",
    "plt.show()\n",
    "returns=np.array(returns['dlr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_prediction(pars,pre=False):\n",
    "    good=(np.exp(pars[:,0])<=1e300)\n",
    "    good&=(pars[:,1]>0)*(pars[:,2]>0)*(pars[:,1]+pars[:,2]<1)\n",
    "    neglogpdfpT=0.5*((pars[:,0]-prior_pars[0])/prior_pars[1])**2\n",
    "    neglogpdfpT[~good]=np.inf\n",
    "    HTd=np.ones(pars.shape[0])\n",
    "    HTd[good]=np.exp(pars[good,0])+pars[good,1]*y0**2+pars[good,2]*h0\n",
    "    for i in range(T):\n",
    "        neglogpdfpT+=0.5*(YT[i]**2/HTd+np.log(HTd))\n",
    "        HTd[good]=np.exp(pars[good,0])+pars[good,1]*YT[i]**2+pars[good,2]*HTd[good]\n",
    "        \n",
    "    if pre:\n",
    "        RYdpart=np.zeros(pars.shape[0])\n",
    "        if d>1:\n",
    "            for i in range(d-1):\n",
    "                Ypre=norm.rvs(scale=np.sqrt(HTd))\n",
    "                RYdpart[good]+=Ypre[good]\n",
    "                HTd[good]=np.exp(pars[good,0])+pars[good,1]*Ypre[good]**2+pars[good,2]*HTd[good]\n",
    "            \n",
    "        return neglogpdfpT,HTd,RYdpart\n",
    "    else:\n",
    "        return neglogpdfpT\n",
    "\n",
    "def MLE():\n",
    "    cons=({'type':'ineq',\\\n",
    "           'fun':lambda pars: np.array([pars[1],pars[2],1-pars[1]+pars[2]]),\\\n",
    "           'jac':lambda x: np.array([[0,1,0],[0,0,1],[0,-1,-1]])})\n",
    "    target=lambda pars: posterior_prediction(pars.reshape([1,3]))\n",
    "    res=minimize(target,[0,0.1,0.7],method='SLSQP',constraints=cons,\\\n",
    "                 options={'maxiter':1000,'ftol':1e-100,'disp':False})\n",
    "    mu=res['x']\n",
    "    Sigma=np.linalg.inv(nd.Hessian(target)(mu))\n",
    "    Sigma[:,0]*=2\n",
    "    Sigma[0,:]*=2\n",
    "    return mu,Sigma\n",
    "\n",
    "def estimation(RYd,W,p):\n",
    "    VaR=quantile(RYd,W,p)\n",
    "    WW=W/np.sum(W)\n",
    "    avar=np.sum((((RYd<=VaR)-p)*WW)**2)*RYd.size\n",
    "    return VaR,avar\n",
    "\n",
    "def MLE_estimation(RYd,pdfp,pdfqs):\n",
    "    pdfg=pdfqs[1:]-pdfqs[0]\n",
    "    pdfq=pdfqs.mean(axis=0)\n",
    "    target=lambda zeta: -np.sum(np.log(pdfq+zeta.reshape([1,-1]).dot(pdfg).flatten()))\n",
    "    gradient=lambda zeta: -np.sum(pdfg/(pdfq+zeta.reshape([1,-1]).dot(pdfg).flatten()),axis=1)\n",
    "    zeta0=np.zeros(pdfg.shape[0])\n",
    "    cons=({'type':'ineq',\\\n",
    "           'fun':lambda zeta: pdfq+zeta.reshape([1,-1]).dot(pdfg).flatten(),\\\n",
    "           'jac':lambda zeta: pdfg.T})\n",
    "    res=minimize(target,zeta0,method='SLSQP',jac=gradient,constraints=cons,\\\n",
    "                 options={'maxiter':1000,'ftol':1e-100,'disp':False})\n",
    "    if res['success']:\n",
    "        zeta=res['x']\n",
    "        tmp=np.append(-zeta.sum(),zeta)\n",
    "        print('MLE',res['nit'],'alpha:',np.ones(pdfqs.shape[0])/pdfqs.shape[0]+tmp)\n",
    "        W=pdfp/(pdfq+zeta.reshape([1,-1]).dot(pdfg).flatten())\n",
    "        print('MLE',RYd.size,'1~4:','VaR0.05:',estimation(RYd,W,0.05)[0],'VaR0.01:',estimation(RYd,W,0.01)[0])\n",
    "    else:\n",
    "        print('MLE fail')\n",
    "\n",
    "def main():\n",
    "    parsN=multi_norm.rvs(size=2*n,mean=mu,cov=Sigma)\n",
    "    parst=np.array([t.rvs(size=2*n,df=1,loc=mu[i],scale=np.sqrt(Sigma[i,i])) for i in range(3)]).T\n",
    "    pars=np.vstack([parsN,parst])\n",
    "    pdfN=multi_norm.pdf(x=pars,mean=mu,cov=Sigma)\n",
    "    pdft=np.prod([t.pdf(x=pars[:,i],df=1,loc=mu[i],scale=np.sqrt(Sigma[i,i])) for i in range(3)],axis=0)\n",
    "    \n",
    "    neglogpdfpT,HTd,RYdpart=posterior_prediction(pars,True)\n",
    "    pdfpT=np.exp(-neglogpdfpT)\n",
    "    good=(neglogpdfpT!=np.inf)\n",
    "    print('Samples in feasible region:',np.mean(good))\n",
    "    \n",
    "    rvs1=norm.rvs(scale=np.sqrt(HTd[:n]))\n",
    "    rvs2=norm.rvs(loc=-np.sqrt(HTd[n:2*n]),scale=np.sqrt(HTd[n:2*n]))\n",
    "    rvs3=norm.rvs(scale=np.sqrt(HTd[2*n:3*n]))\n",
    "    rvs4=norm.rvs(loc=-np.sqrt(HTd[3*n:4*n]),scale=np.sqrt(HTd[3*n:4*n]))\n",
    "    YTd=np.hstack([rvs1,rvs2,rvs3,rvs4])\n",
    "    RYd=RYdpart+YTd\n",
    "    \n",
    "    pdfq1=norm.pdf(x=YTd,scale=np.sqrt(HTd))\n",
    "    pdfq2=norm.pdf(x=YTd,loc=-np.sqrt(HTd),scale=np.sqrt(HTd))\n",
    "    pdfq1N=pdfN*pdfq1\n",
    "    pdfq2N=pdfN*pdfq2\n",
    "    pdfq1t=pdft*pdfq1\n",
    "    pdfq2t=pdft*pdfq2\n",
    "    \n",
    "    pdfqs=np.array([pdfq1N,pdfq2N,pdfq1t,pdfq2t])\n",
    "    pdfp=pdfpT*pdfq1\n",
    "    W=pdfp/pdfqs.mean(axis=0)\n",
    "    W0=pdfp/pdfqs[:2].mean(axis=0)\n",
    "    W0=W0[:2*n]\n",
    "    W1=pdfp/pdfqs[2:].mean(axis=0)\n",
    "    W1=W1[2*n:]\n",
    "    print(2*n,'1~2:','VaR0.05:',estimation(RYd[:2*n],W0,0.05),'VaR0.01:',estimation(RYd[:2*n],W0,0.01))\n",
    "    print(2*n,'3~4:','VaR0.05:',estimation(RYd[2*n:],W1,0.05),'VaR0.01:',estimation(RYd[2*n:],W1,0.01))\n",
    "    print(4*n,'1~4:','VaR0.05:',estimation(RYd,W,0.05),'VaR0.01:',estimation(RYd,W,0.01))\n",
    "    \n",
    "    MLE_estimation(RYd,pdfp,pdfqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0=np.std(returns)\n",
    "y0=returns[0]\n",
    "YT=returns[1:]\n",
    "T=YT.size\n",
    "prior_pars=[-1,2]\n",
    "D=[1,2,5]\n",
    "truth=np.array([[-1.333,-1.895],[-1.886,-2.771],[-2.996,-4.424]])\n",
    "n=200000\n",
    "np.random.seed(1)\n",
    "for i,d in enumerate(D):\n",
    "    print('Reference for d = '+str(d)+':','VaR0.05:',truth[i,0],'VaR0.01:',truth[i,1])\n",
    "    mu,Sigma=MLE()\n",
    "    main()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "for i,d in enumerate(D):\n",
    "    print('Reference for d = '+str(d)+':','VaR0.05:',truth[i,0],'VaR0.01:',truth[i,1])\n",
    "    mu,Sigma=MLE()\n",
    "    main()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "for i,d in enumerate(D):\n",
    "    print('Reference for d = '+str(d)+':','VaR0.05:',truth[i,0],'VaR0.01:',truth[i,1])\n",
    "    mu,Sigma=MLE()\n",
    "    main()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
